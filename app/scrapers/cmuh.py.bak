"""
CMUH (中國醫藥大學附設醫院) Scraper

Scrapes:
1. /OnlineAppointment/AppointmentByDivision?flag=first  → department list
2. /OnlineAppointment/DymSchedule?table={code}&flag=first → doctor schedules
3. /OnlineAppointment/DoctorInfo?DocNo={no}             → appointment counts
4. /OnlineAppointment/ClinicQuery                       → current queue number
"""

import asyncio
import re
from datetime import date, datetime
from typing import Optional

import httpx
from bs4 import BeautifulSoup
from tenacity import retry, stop_after_attempt, wait_exponential

from app.core.logger import logger as log
from app.scrapers.base import BaseScraper, DepartmentData, DoctorSlot, ClinicProgress
from app.config import get_settings

settings = get_settings()

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/121.0.0.0 Safari/537.36"
    ),
    "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Referer": "https://www.cmuh.cmu.edu.tw/",
}


def _parse_int(text: Optional[str]) -> Optional[int]:
    """Extract first integer from a string."""
    if not text:
        return None
    m = re.search(r"\d+", text.strip())
    return int(m.group()) if m else None


class CMUHScraper(BaseScraper):
    HOSPITAL_CODE = "CMUH"
    BASE_URL = "https://www.cmuh.cmu.edu.tw"
    CGI_BASE_URL = "https://appointment.cmuh.org.tw/cgi-bin"
    PROGRESS_CGI = "reg64.cgi"

    def __init__(self):
        self._client: Optional[httpx.AsyncClient] = None

    async def _get_client(self) -> httpx.AsyncClient:
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                headers=HEADERS,
                timeout=settings.request_timeout,
                follow_redirects=True,
            )
        return self._client

    async def close(self):
        if self._client and not self._client.is_closed:
            await self._client.aclose()

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def _get(self, url: str, **kwargs) -> str:
        from app.core.logger import logger as log
        log.info(f"[CMUH] GET {url} with params {kwargs.get('params')}")
        client = await self._get_client()
        resp = await client.get(url, **kwargs)
        resp.raise_for_status()
        log.info(f"[CMUH] GET {url} success ({len(resp.text)} chars)")
        return resp.text

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
    async def _post(self, url: str, data: dict) -> str:
        client = await self._get_client()
        resp = await client.post(url, data=data)
        resp.raise_for_status()
        return resp.text

    # ─────────────────────────────────────────────────────────
    # 1. Fetch department list
    # ─────────────────────────────────────────────────────────
    async def fetch_departments(self) -> list[DepartmentData]:
        url = f"{self.BASE_URL}/OnlineAppointment/AppointmentByDivision"
        html = await self._get(url, params={"flag": "first"})
        soup = BeautifulSoup(html, "lxml")

        departments: list[DepartmentData] = []

        # CMUH Main Hospital has category boxes: onlinedivision_box
        boxes = soup.find_all("div", class_="onlinedivision_box")
        current_sort_order = 1
        if boxes:
            for box in boxes:
                title_div = box.find("div", class_="title")
                category = title_div.get_text(strip=True) if title_div else None
                
                for a in box.find_all("a", href=True):
                    href = a["href"]
                    m = re.search(r"table=([A-Za-z0-9]+)", href)
                    if m:
                        code = m.group(1)
                        name = a.get_text(strip=True)
                        if name:
                            departments.append(
                                DepartmentData(
                                    name=name,
                                    code=code,
                                    hospital_code=self.HOSPITAL_CODE,
                                    category=category,
                                    sort_order=current_sort_order
                                )
                            )
                            current_sort_order += 1
        else:
            # Fallback for pages without standard category boxes (e.g. Hsinchu if it used this base)
            for a in soup.find_all("a", href=True):
                href = a["href"]
                m = re.search(r"table=([A-Za-z0-9]+)", href)
                if m:
                    code = m.group(1)
                    name = a.get_text(strip=True)
                    if name:
                        departments.append(
                            DepartmentData(
                                name=name,
                                code=code,
                                hospital_code=self.HOSPITAL_CODE,
                                category=None,
                                sort_order=current_sort_order
                            )
                        )
                        current_sort_order += 1

        # Deduplicate by code
        seen = set()
        unique: list[DepartmentData] = []
        for d in departments:
            if d.code not in seen:
                seen.add(d.code)
                unique.append(d)
        return unique

    # ─────────────────────────────────────────────────────────
    # 2. Fetch doctor slots for a department
    # ─────────────────────────────────────────────────────────
    async def fetch_schedule(self, dept_code: str) -> list[DoctorSlot]:
        log.info(f"[CMUH] fetch_schedule for {dept_code} ({self.BASE_URL})")
        url = f"{self.BASE_URL}/OnlineAppointment/DymSchedule"
        html = await self._get(url, params={"table": dept_code, "flag": "first"})
        log.info(f"[CMUH] fetch_schedule got HTML for {dept_code}")
        soup = BeautifulSoup(html, "lxml")

        slots: list[DoctorSlot] = []
        today = date.today()

        # The schedule is rendered as a table/div grid
        # Each row typically has: doctor name, date, session type, quota, registered, status
        # We'll look for all doctor links first, then scrape doctor details
        doctor_links = []
        for a in soup.find_all("a", href=True):
            href = a["href"]
            m = re.search(r"DocNo=([A-Za-z0-9]+)", href)
            if m:
                doc_no = m.group(1)
                doc_name = a.get_text(strip=True)
                if doc_name and doc_no not in [d[0] for d in doctor_links]:
                    doctor_links.append((doc_no, doc_name))

        # Fetch details for all doctors concurrently (limit concurrency)
        sem = asyncio.Semaphore(5)

        async def fetch_one(doc_no: str, doc_name: str):
            async with sem:
                return await self._fetch_doctor_slots(doc_no, doc_name, dept_code)

        results = await asyncio.gather(
            *[fetch_one(no, name) for no, name in doctor_links],
            return_exceptions=True,
        )
        for r in results:
            if isinstance(r, list):
                slots.extend(r)
        return slots

    # ─────────────────────────────────────────────────────────
    # 3. Fetch individual doctor appointment details
    # ─────────────────────────────────────────────────────────
    async def _fetch_doctor_slots(
        self, doc_no: str, doc_name: str, dept_code: str
    ) -> list[DoctorSlot]:
        # The doctor info page on the main site is just a shell.
        # The actual schedule is in an iframe pointing to the appointment backend.
        # Doctor IDs in the appointment backend need a 'D' prefix.
        appointment_doc_no = f"D{doc_no}" if not doc_no.startswith("D") else doc_no
        url = f"{self.CGI_BASE_URL}/reg52.cgi"
        
        client = await self._get_client()
        html = ""
        for attempt in range(3):
            try:
                # Need to handle Big5/CP950 encoding from the CGI backend
                resp = await client.get(url, params={"DocNo": appointment_doc_no, "Docname": doc_name})
                resp.raise_for_status()
                html = resp.content.decode("big5", errors="ignore")
                break
            except Exception as e:
                if attempt == 2:
                    print(f"Error fetching doctor info for {doc_no} after 3 attempts: {e}")
                    return []
                import asyncio
                await asyncio.sleep(1.0 * (attempt + 1))
                
        if not html:
            return []

        soup = BeautifulSoup(html, "lxml")
        slots: list[DoctorSlot] = []

        # The CGI backend returns a table where each row's first cell is the session time.
        # The other cells (columns 2-8) correspond to days of the week.
        # Each cell (schBox) can contain multiple date blocks if the doctor has multiple clinics.
        # Example: 115/02/23已掛號：58 人(230診)115/03/02...
        rows = soup.find_all("tr")
        for row in rows:
            cells = row.find_all(["td", "th"])
            if not cells:
                continue

            session_text = cells[0].get_text(strip=True)
            session_type = self._normalize_session_type(session_text)
            
            # Skip rows that aren't session rows (e.g. header rows)
            if session_type == session_text and not any(s in session_text for s in ["上午", "下午", "晚上"]):
                continue

            # Iterate through columns (days of the week)
            for cell in cells[1:]:
                text = cell.get_text(strip=True)
                if not text:
                    continue

                # Use regex to find all date blocks in the cell
                # Pattern: ROC date (11x/xx/xx) followed by optional registration/room info
                # We split the cell text by the date pattern
                matches = list(re.finditer(r"(\d{3}/\d{2}/\d{2})", text))
                if not matches:
                    continue

                # Add a dummy end position to handle the last block
                positions = [m.start() for m in matches]
                positions.append(len(text))

                for i in range(len(matches)):
                    block = text[positions[i] : positions[i + 1]]
                    
                    # Parse block details
                    d_str = matches[i].group(1)
                    session_date = self._parse_date(d_str)
                    if not session_date:
                        continue

                    registered = _parse_int(re.search(r"已掛號[：:]\s*(\d+)", block).group(1)) if re.search(r"已掛號[：:]\s*(\d+)", block) else None
                    
                    # Find all potential room numbers and pick the longest one
                    room_matches = re.findall(r"\((\w+)診?\)", block)
                    clinic_room = max(room_matches, key=len) if room_matches else None
                    
                    # Extract current calling number (診間燈號)
                    # Pattern on page: <div style="text-align:center;">診間燈號：37</div>
                    lamp_match = re.search(r"診間燈號[：:]\s*(\d+)", block)
                    current_number = int(lamp_match.group(1)) if lamp_match else None

                    is_full = "額滿" in block or "掛滿" in block
                    status_text = "額滿" if is_full else None

                    slots.append(
                        DoctorSlot(
                            doctor_no=doc_no,
                            doctor_name=doc_name,
                            department_code=dept_code,
                            session_date=session_date,
                            session_type=session_type,
                            total_quota=None,           # CGI doesn't easily show quota
                            registered=registered,
                            clinic_room=clinic_room,
                            current_number=current_number,
                            is_full=is_full,
                            status=status_text,
                        )
                    )
        return slots

    # ─────────────────────────────────────────────────────────
    # 4. Fetch clinic queue progress
    # ─────────────────────────────────────────────────────────
    async def fetch_clinic_progress(
        self, room: str, period: str
    ) -> Optional[ClinicProgress]:
        """
        Query current calling number and clinic status using reg64.cgi.
        period: '1'=morning, '2'=afternoon, '3'=evening
        """
        url = f"{self.CGI_BASE_URL}/{self.PROGRESS_CGI}"
        
        # Room passed from DB already has '診' stripped by the upstream method
        params = {"TimeCode": period, "CliRoom": room.strip()}
        try:
            client = await self._get_client()
            # reg64.cgi responds with Big5 encoding
            resp = await client.get(url, params=params)
            resp.raise_for_status()
            html = resp.content.decode("big5", errors="ignore")
        except Exception as e:
            # Fallback to old behavior if reg64 fails, or just return None
            return None

        soup = BeautifulSoup(html, "lxml")
        
        current_number = None
        status = None
        
        # 1. Extract Current Number & Basic Status
        # Look for the specific line: 診間目前燈號：24 or 看診完畢
        text_all = soup.get_text()
        html_all = str(soup)
        
        # Look for the specific pattern in raw HTML (since they added tags)
        # e.g.: 目前診號 <span class="text-primary"><strong>104</strong></span>
        # or old versions: 目前燈號：24, 目前的診號是 37
        lamp_match = re.search(r"目前[的]?[燈診]號.*?(\d+)", html_all)
        if lamp_match:
            current_number = int(lamp_match.group(1))
        
        if "看診完畢" in text_all or "掛號看診完畢" in text_all:
            status = "看診完畢"
            if current_number is None: current_number = 0
        elif "未開診" in text_all:
            status = "未開診"
            if current_number is None: current_number = 0
        elif "休診" in text_all:
            status = "休診"
            if current_number is None: current_number = 0

        # 2. Extract Quota and Registered Count from table
        numbers = []
        waiting_list = []
        patient_rows = 0
        rows = soup.find_all("tr")
        for row in rows:
            tds = row.find_all("td")
            if len(tds) >= 2: # Look for rows with [Number, Status]
                val_str = tds[0].get_text(strip=True)
                val_status = tds[1].get_text(strip=True)
                val = _parse_int(val_str)
                # Ensure it's not a header row by checking if it contains a pure number
                if val is not None and val_str.isdigit():
                    numbers.append(val)
                    patient_rows += 1
                    if val_status == "未看診":
                        waiting_list.append(val)

        max_num = max(numbers) if numbers else 0
        headcount = patient_rows

        if current_number is None and not status:
            return None

        period_map = {"1": "上午", "2": "下午", "3": "晚上"}
        return ClinicProgress(
            clinic_room=room,
            session_type=period_map.get(period, period),
            current_number=current_number or 0,
            total_quota=max_num,        # Maximum Number
            registered_count=headcount, # Headcount
            status=status,
            waiting_list=waiting_list
        )

    # ─────────────────────────────────────────────────────────
    # Helpers
    # ─────────────────────────────────────────────────────────
    @staticmethod
    def _parse_date(text: str) -> Optional[date]:
        text = text.strip()
        # Support formats: 2024/01/15, 2024-01-15, 113/01/15 (ROC year)
        patterns = [
            (r"(\d{4})[/\-](\d{1,2})[/\-](\d{1,2})", False),  # AD year
            (r"(\d{3})[/\-](\d{1,2})[/\-](\d{1,2})", True),   # ROC year
        ]
        for pat, is_roc in patterns:
            m = re.search(pat, text)
            if m:
                y, mo, d = int(m.group(1)), int(m.group(2)), int(m.group(3))
                if is_roc:
                    y += 1911
                try:
                    return date(y, mo, d)
                except ValueError:
                    continue
        return None

    @staticmethod
    def _normalize_session_type(text: str) -> str:
        if "上午" in text or "morning" in text.lower() or "AM" in text:
            return "上午"
        if "下午" in text or "afternoon" in text.lower() or "PM" in text:
            return "下午"
        if "晚上" in text or "evening" in text.lower() or "night" in text.lower():
            return "晚上"
        return text.strip() or "上午"


class CMUHHsinchuScraper(CMUHScraper):
    HOSPITAL_CODE = "CMUH_HS"
    BASE_URL = "https://www.cmu-hch.cmu.edu.tw"
    CGI_BASE_URL = "https://www.cmu-hch.com/cgi-bin/hc"
    PROGRESS_CGI = "reg64x.cgi"

    async def fetch_departments(self) -> list[DepartmentData]:
        depts = await super().fetch_departments()

        category_map = {
            "一般內科": "內科系",
            "神經科": "內科系",
            "心臟血管科": "內科系",
            "胸腔暨重症科": "內科系",
            "消化科(腸胃肝膽)": "內科系",
            "腎臟科": "內科系",
            "風濕免疫科": "內科系",
            "內分泌暨新陳代謝科": "內科系",
            "感染科": "內科系",
            "家庭醫學科": "內科系",
            "職業醫學科": "內科系",
            "精神醫學科": "內科系",
            "臨床營養科": "內科系",
            "放射腫瘤科": "內科系",
            "血液腫瘤科": "內科系",
            
            "一般外科": "外科系",
            "乳房外科": "外科系",
            "減重外科": "外科系",
            "心臟血管外科": "外科系",
            "胸腔外科": "外科系",
            "大腸直腸外科": "外科系",
            "整形外科": "外科系",
            "泌尿科": "外科系",
            "神經外科": "外科系",
            "骨科": "外科系",

            "兒科": "婦兒科系",
            "小兒外科": "婦兒科系",
            "小兒心臟科": "婦兒科系",
            "婦產科": "婦兒科系",
            "不孕症門診": "婦兒科系",

            "中醫科": "中醫科系",

            "眼科": "其他專科",
            "耳鼻喉科": "其他專科",
            "牙科": "其他專科",
            "復健科": "其他專科",
            "皮膚科": "其他專科",
        }

        for d in depts:
            d.category = category_map.get(d.name, "其他專科")

        return depts
